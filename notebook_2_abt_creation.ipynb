{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines workshop 2: creating an ABT\n",
    "\n",
    "In the first notebook for this workshop, \"importing and preparing the data\" you read in data from an external source and processed it into two CSV files: data/processed/income.csv and data/processed/expenditure.csv.\n",
    "\n",
    "This data consists of information on household incomes and household expenditures, both provided by the Dutch national statistics bureau CBS. \n",
    "\n",
    "In this notebook we are going to combine the two CSV files into one large table so that we can analyze link between household expenses and household income. A table in which multiple data sets are combined so they can be analyzed together is known as an Analytical Base Table (ABT).\n",
    "\n",
    "As this notebook, too, is part of our pipeline, we will be rigorously logging  all the unexpected situations we encounter in our work.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.utils import *\n",
    "from loguru import logger\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our data\n",
    "\n",
    "Reading in our data should not cause problems, but just in case it does: log errors and halt execution if one of our two data files does not exist.\n",
    "\n",
    "- Load income data into a dataframe `dfi`\n",
    "- Load expenditure data into a dataframe `dfe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing sanity checks\n",
    "\n",
    "Before we proceed, we need to check our data to see if it contains the type of values we expect.\n",
    "\n",
    "Let's do this for the \"expenditure\" file:\n",
    "\n",
    "- Year should be a reasonable value (between 2010 and the current year, say)\n",
    "- The value in the \"all\" column should be higher than the values in the other columns combined (it does not need to be *equal* to those columns because we left out a number of expenditure categories during the data import).\n",
    "- The same is true for the \"housing_energy\" column: its value should be higher than that of the \"energy\" column.\n",
    "\n",
    "Before we get started, we need to think about what we want to do when the files turn out to be incorrect. In the first notebook, we logged a critical error and aborted the import. This made sense, because we don't want to create invalid data files for the rest of the process.\n",
    "\n",
    "We could argue we are doing similar here, because we're creating an ABT. However, if we halt the process as soon as we encounter our first error, we will not know if the rest of the process is error free. What we want, is to let the entire process run, log any errors that we encounter and only at the end, before we save the final ABT file, do we want to exit if any errors were encountered.\n",
    "\n",
    "So what we will do is store the number of errors encountered in a variable. Then, at the end, when that number is greater than zero, we will report it and exit before combining the two data sets into a single ABT file.\n",
    "\n",
    "Meanwhile, every time we encounter an error we will either log it or raise an exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable counting the number of errors encountered.\n",
    "num_errors = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the year value contains reasonable values\n",
    "if len(dfe[(dfe['year'] > 2010) & (dfe['year'] < datetime.now().year) ]) != len(dfe):\n",
    "    num_errors += 1\n",
    "    # Raising an exception halts execution in the current cell.\n",
    "    raise Exception(\"Invalid expenditure file: contains invalid year values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the values in the 'all' column are larger than those in the other columns\n",
    "# (except 'energy' as that is part of 'housing_energy')\n",
    "dfe_validate_num_cols = pd.DataFrame(dfe['all'])\n",
    "dfe_validate_num_cols['other'] = dfe[['food','alc_tobacco','clothes','housing_energy', 'transportation']].sum(axis = 1)\n",
    "if len(dfe_validate_num_cols[dfe_validate_num_cols['all'] < dfe_validate_num_cols['other']]) > 0:\n",
    "    num_errors += 1\n",
    "    # Don't raise an exception because we want to continue executing code in this cell.\n",
    "    logger.error(\"Invalid expenditure file: other columns combined are larger than the 'all' column\")\n",
    "\n",
    "# Check if 'energy' is less than 'housing_energy')\n",
    "# if len(dfe['housing_energy'])\n",
    "if len(dfe[dfe['housing_energy'] < dfe['energy']]) > 0:\n",
    "    num_errors += 1\n",
    "    logger.error(\"Invalid expenditure file: energy is larger than housing and energy combined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're done with the expenses data, we can start validating the income data. You can do this yourself, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to check if we can join our two data frames. For this to be possible, the values in the 'year' columns for both files must match. Since we know the incomes file has more data than the expenses file, we are satisfied if the years in the expenses file are present in the years column in the income file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if values from the expenses file occur in the incomes file we use Python's built-in \"set\" function\n",
    "smallest_set = set(dfe['year'])\n",
    "largest_set = set(dfi['year'])\n",
    "# Subtracting sets like this yields all values that are in smallest_set that are not in largest_set\n",
    "if smallest_set - largest_set:\n",
    "    num_errors += 1\n",
    "    logger.error('Not all years in the smallest data set occur in the largest data set')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining data frames together\n",
    "\n",
    "We can now join the two data sets together - *if* we haven't encountered any errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_errors > 0:\n",
    "    logger.critical(\"Errors were encountered in CSV files. Aborting.\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're still here, we can start joining.\n",
    "\n",
    "The problem is that the incomes file has much more data than the expenses file. This means we need to filter out all the rows from the expenses data for which no matching incomes row can be found. We could simply drop them, but this would cause us to lose information on changes in incomes in the years for which no data is available in the expenses file.\n",
    "\n",
    "Let's add an extra column to the incomes file that holds the change in total income compared to the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi['total_inc_prev_mill'] = dfi['total_inc_mill'].shift(1)\n",
    "dfi['total_inc_delta_mill'] = dfi['total_inc_mill'] - dfi['total_inc_prev_mill']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the columns mean_inc_k, median_inc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, drop the rows in the income data frame for which no matching row exists in the expenses data frame and perform the join.\n",
    "\n",
    "Note that while Pandas has a `join` method this should not be used for joining two data frames like this (it can only join on indexes). Instead you have to use the `merge` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_hh</th>\n",
       "      <th>total_inc_mill</th>\n",
       "      <th>mean_inc_k</th>\n",
       "      <th>median_inc_k</th>\n",
       "      <th>total_inc_mill_prev</th>\n",
       "      <th>total_inc_prev_mill</th>\n",
       "      <th>total_inc_delta_mill</th>\n",
       "      <th>all</th>\n",
       "      <th>food</th>\n",
       "      <th>alc_tobacco</th>\n",
       "      <th>clothes</th>\n",
       "      <th>housing_energy</th>\n",
       "      <th>energy</th>\n",
       "      <th>transportation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>7568.5</td>\n",
       "      <td>292094.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>32.5</td>\n",
       "      <td>306084.0</td>\n",
       "      <td>292108.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>33763.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>10646.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>4351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>7894.5</td>\n",
       "      <td>366657.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>38.1</td>\n",
       "      <td>385822.0</td>\n",
       "      <td>357843.0</td>\n",
       "      <td>8814.0</td>\n",
       "      <td>35211.0</td>\n",
       "      <td>4458.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>11577.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>3955.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  num_hh  total_inc_mill  mean_inc_k  median_inc_k  \\\n",
       "0  2015  7568.5        292094.0        38.6          32.5   \n",
       "1  2020  7894.5        366657.0        46.4          38.1   \n",
       "\n",
       "   total_inc_mill_prev  total_inc_prev_mill  total_inc_delta_mill      all  \\\n",
       "0             306084.0             292108.0                 -14.0  33763.0   \n",
       "1             385822.0             357843.0                8814.0  35211.0   \n",
       "\n",
       "     food  alc_tobacco  clothes  housing_energy  energy  transportation  \n",
       "0  3721.0       1014.0   1591.0         10646.0  1582.0          4351.0  \n",
       "1  4458.0       1222.0   1394.0         11577.0  1540.0          3955.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined = pd.merge(dfi[dfi['year'].isin(dfe['year'])], dfe)\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the joined data frame to a csv file (don't forget to log the timestamp for when you did this! )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logfile = 'data/processed/abt.csv.log'\n",
    "csv_file = 'data/processed/abt.csv'\n",
    "# Your code goes here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "Congratulations! You now have created a robust pipeline process for importing data from the internet, cleaning it up and validating its contents.\n",
    "\n",
    "A pipeline like this can be handed over to an ML engineer or a dev ops engineer for deployment. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
