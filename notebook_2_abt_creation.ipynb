{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines workshop 2: creating an ABT\n",
    "\n",
    "In the first notebook for this workshop, \"importing and preparing the data\" you read in data from an external source and processed it into two CSV files: data/processed/income.csv and data/processed/expenditure.csv.\n",
    "\n",
    "This data consists of information on household incomes and household expenditures, both provided by the Dutch national statistics bureau CBS. \n",
    "\n",
    "In this notebook we are going to combine the two CSV files into one large table so that we can analyze link between household expenses and household income. A table in which multiple data sets are combined so they can be analyzed together is known as an Analytical Base Table (ABT).\n",
    "\n",
    "As this notebook, too, is part of our pipeline, we will be rigorously logging  all the unexpected situations we encounter in our work.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lib.utils import *\n",
    "from loguru import logger\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our data\n",
    "\n",
    "Reading in our data should not cause problems, but just in case it does: log errors and halt execution if one of our two data files does not exist.\n",
    "\n",
    "- Load income data into a dataframe `dfi`\n",
    "- Load expenditure data into a dataframe `dfe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dfi = pd.read_csv(\"data/processed/income.csv\")\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Unable to read income csv file: {e}\")\n",
    "    exit(0)\n",
    "\n",
    "try:\n",
    "    dfe = pd.read_csv(\"data/processed/expenditure.csv\")\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Unable to read expenditure csv file: {e}\")\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing sanity checks\n",
    "\n",
    "Before we proceed, we need to check our data to see if it contains the type of values we expect.\n",
    "\n",
    "Let's do this for the \"expenditure\" file:\n",
    "\n",
    "- Year should be a reasonable value (between 2010 and the current year, say)\n",
    "- The value in the \"all\" column should be higher than the values in the other columns combined (it does not need to be *equal* to those columns because we left out a number of expenditure categories during the data import).\n",
    "- The same is true for the \"housing_energy\" column: its value should be higher than that of the \"energy\" column.\n",
    "\n",
    "Before we get started, we need to think about what we want to do when the files turn out to be incorrect. In the first notebook, we logged a critical error and aborted the import. This made sense, because we don't want to create invalid data files for the rest of the process.\n",
    "\n",
    "We could argue we are doing similar here, because we're creating an ABT. However, if we halt the process as soon as we encounter our first error, we will not know if the rest of the process is error free. What we want, is to let the entire process run, log any errors that we encounter and only at the end, before we save the final ABT file, do we want to exit if any errors were encountered.\n",
    "\n",
    "So what we will do is store the number of errors encountered in a variable. Then, at the end, when that number is greater than zero, we will report it and exit before writing the ABT file.\n",
    "\n",
    "Meanwhile, every time we encounter an error we will either log it or raise an exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable counting the number of errors encountered.\n",
    "num_errors = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the year value contains reasonable values\n",
    "if len(dfe[(dfe['year'] > 2010) & (dfe['year'] < datetime.now().year) ]) != len(dfe):\n",
    "    num_errors += 1\n",
    "    # Raising an exception halts execution in the current cell.\n",
    "    raise Exception(\"Invalid expenditure file: contains invalid year values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the values in the 'all' column are larger than those in the other columns\n",
    "# (except 'energy' as that is part of 'housing_energy')\n",
    "dfe_validate_num_cols = pd.DataFrame(dfe['all'])\n",
    "dfe_validate_num_cols['other'] = dfe[['food','alc_tobacco','clothes','housing_energy', 'transportation']].sum(axis = 1)\n",
    "if len(dfe_validate_num_cols[dfe_validate_num_cols['all'] < dfe_validate_num_cols['other']]) > 0:\n",
    "    num_errors += 1\n",
    "    # Don't raise an exception because we want to continue executing code in this cell.\n",
    "    logger.error(\"Invalid expenditure file: other columns combined are larger than the 'all' column\")\n",
    "\n",
    "# Check if 'energy' is less than 'housing_energy')\n",
    "# if len(dfe['housing_energy'])\n",
    "if len(dfe[dfe['housing_energy'] < dfe['energy']]) > 0:\n",
    "    num_errors += 1\n",
    "    logger.error(\"Invalid expenditure file: energy is larger than housing and energy combined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're done with the expenses data, we can start validating the income data. You can do this yourself, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
